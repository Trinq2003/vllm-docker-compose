version: '3.8'

services:
  vllm-qwen25-14b-instruct-1m:
    image: vllm/vllm-openai:v0.10.1
    container_name: vllm-qwen25-14b-instruct-1m
    networks:
      - shared-vllm-network
    ports:
      - "9998:8000"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - VLLM_ATTENTION_BACKEND=FLASHINFER
      - VLLM_USE_FLASH_ATTN=1
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['2']
              capabilities: [gpu]
    command: >
      --model Qwen/Qwen2.5-14B-Instruct-1M
      --host 0.0.0.0
      --port 8001
      --tensor-parallel-size 1
      --gpu-memory-utilization 0.95
      --max-model-len 329152
      --trust-remote-code
      --enable-auto-tool-choice
      --tool-call-parser hermes
    restart: unless-stopped

networks:
  shared-vllm-network:
    external: true